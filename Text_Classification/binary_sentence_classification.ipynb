{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- You must manually change the env into text_classification environment\n",
    "You need to run in terminal:\n",
    "\n",
    "```sh\n",
    "conda env create -f env.yml\n",
    "```\n",
    "Then, you need to activate text_classification environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Fine-tuning a BERT model for single-sentence binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/v3/envs/text_classification/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "import torch\n",
    "from torch import cuda\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd \n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "# Early stopping callback\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Device configuration\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f'./results_{timestamp}'\n",
    "log_dir = f'./logs_{timestamp}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained model and tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "# id2label and label2id are passed to the model to use during inference.\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path,\n",
    "                                                            id2label={\n",
    "                                                                0: \"NEG\", 1: \"POS\"},\n",
    "                                                            label2id={\"NEG\": 0, \"POS\": 1}).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading popular IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 336773.95 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 351937.28 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 383772.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_train shape: (25000, 2)\n",
      "imdb_test shape: (12500, 2)\n",
      "imdb_val shape: (12500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading IMDB dataset...\")\n",
    "imdb_train = load_dataset('imdb', split='train', download_mode=\"force_redownload\")\n",
    "# Fixed indentation and spacing in the following lines\n",
    "imdb_test_start = load_dataset('imdb', split='test[:6250]') \n",
    "imdb_test_end = load_dataset('imdb', split='test[-6250:]') \n",
    "# Concatenate the two datasets using concatenate_datasets\n",
    "imdb_test = concatenate_datasets([imdb_test_start, imdb_test_end])\n",
    "\n",
    "imdb_val_start = load_dataset('imdb', split='test[6250:12500]')\n",
    "imdb_val_end = load_dataset('imdb', split='test[-12500:-6250]')\n",
    "imdb_val = concatenate_datasets([imdb_val_start, imdb_val_end])\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(f\"imdb_train shape: {imdb_train.shape}\")\n",
    "print(f\"imdb_test shape: {imdb_test.shape}\")\n",
    "print(f\"imdb_val shape: {imdb_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass these dataset to the tokenizer model to make them ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing training data: 100%|██████████| 25000/25000 [00:05<00:00, 4491.42 examples/s]\n",
      "Tokenizing test data: 100%|██████████| 12500/12500 [00:02<00:00, 4462.95 examples/s]\n",
      "Tokenizing validation data: 100%|██████████| 12500/12500 [00:02<00:00, 4413.03 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of tokenized training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids_shape</th>\n",
       "      <th>attention_mask_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>(512,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>(512,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>(512,)</td>\n",
       "      <td>(512,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label input_ids_shape  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0          (512,)   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0          (512,)   \n",
       "2  If only to avoid making this type of film in t...      0          (512,)   \n",
       "\n",
       "  attention_mask_shape  \n",
       "0               (512,)  \n",
       "1               (512,)  \n",
       "2               (512,)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        truncation=True, \n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Tokenizing datasets...\")\n",
    "enc_train = imdb_train.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    batch_size=64,\n",
    "    desc=\"Tokenizing training data\"\n",
    ")\n",
    "enc_test = imdb_test.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    batch_size=64,\n",
    "    desc=\"Tokenizing test data\"\n",
    ")\n",
    "enc_val = imdb_val.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    batch_size=64,\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "# Set format for PyTorch\n",
    "enc_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "enc_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "enc_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Display sample of tokenized data\n",
    "print(\"Sample of tokenized training data:\")\n",
    "pd.DataFrame({\n",
    "    'text': enc_train['text'][:3],\n",
    "    'label': enc_train['label'][:3],\n",
    "    'input_ids_shape': [ids.shape for ids in enc_train['input_ids'][:3]],\n",
    "    'attention_mask_shape': [mask.shape for mask in enc_train['attention_mask'][:3]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/v3/envs/text_classification/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "EarlyStoppingCallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7029' max='7810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7029/7810 43:42 < 04:51, 2.68 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.243271</td>\n",
       "      <td>0.902529</td>\n",
       "      <td>0.897007</td>\n",
       "      <td>0.950538</td>\n",
       "      <td>0.849183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.239724</td>\n",
       "      <td>0.903809</td>\n",
       "      <td>0.897685</td>\n",
       "      <td>0.958379</td>\n",
       "      <td>0.844220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.274593</td>\n",
       "      <td>0.926536</td>\n",
       "      <td>0.925848</td>\n",
       "      <td>0.934301</td>\n",
       "      <td>0.917547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.926777</td>\n",
       "      <td>0.925604</td>\n",
       "      <td>0.940360</td>\n",
       "      <td>0.911303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.407298</td>\n",
       "      <td>0.921015</td>\n",
       "      <td>0.919290</td>\n",
       "      <td>0.939495</td>\n",
       "      <td>0.899936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.424802</td>\n",
       "      <td>0.928217</td>\n",
       "      <td>0.929675</td>\n",
       "      <td>0.910893</td>\n",
       "      <td>0.949248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.431310</td>\n",
       "      <td>0.929337</td>\n",
       "      <td>0.929298</td>\n",
       "      <td>0.929521</td>\n",
       "      <td>0.929075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.483881</td>\n",
       "      <td>0.927737</td>\n",
       "      <td>0.927030</td>\n",
       "      <td>0.935879</td>\n",
       "      <td>0.918348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.514327</td>\n",
       "      <td>0.926296</td>\n",
       "      <td>0.925128</td>\n",
       "      <td>0.939719</td>\n",
       "      <td>0.910983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "TrainOutput(global_step=7029, training_loss=0.08254671909698366, metrics={'train_runtime': 2622.9307, 'train_samples_per_second': 95.313, 'train_steps_per_second': 2.978, 'total_flos': 2.979562704489677e+16, 'train_loss': 0.08254671909698366, 'epoch': 9.0})\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# TrainingArguments setup\n",
    "# TrainingArguments setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # output directory for model predictions and checkpoints\n",
    "    num_train_epochs=10,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # reduced batch size to prevent CUDA OOM errors\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    warmup_ratio=0.1,  # ratio of warmup steps - more flexible than fixed steps\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=log_dir,  # directory to save logs\n",
    "    do_eval=True,  # whether to evaluate during training\n",
    "    do_train=True,  # whether to train the model\n",
    "    save_strategy='epoch',  # save the model after each epoch\n",
    "    evaluation_strategy='epoch',  # evaluate the model after each epoch\n",
    "    logging_strategy='steps',  # log steps instead of epochs for more frequent updates\n",
    "    report_to='tensorboard',  # report logs to TensorBoard\n",
    "    logging_steps=100,  # how often to log the training loss\n",
    "    fp16=True if cuda.is_available() else False,  # whether to use mixed precision training\n",
    "    load_best_model_at_end=True,  # load the best model when finished training\n",
    "    metric_for_best_model='f1',  # use F1 score to determine best model\n",
    "    greater_is_better=True,  # higher F1 is better\n",
    "    seed=seed,\n",
    "    dataloader_drop_last=True,  # drop last incomplete batch\n",
    "    gradient_accumulation_steps=2,  # accumulate gradients for effective larger batch size\n",
    "    save_total_limit=3,  # limit the total amount of checkpoints saved\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=enc_train,\n",
    "    eval_dataset=enc_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=3),\n",
    "        TensorBoardCallback()\n",
    "    ]\n",
    ")\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "results = trainer.train()\n",
    "print(\"Training completed!\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='781' max='781' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [781/781 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.40319886803627014, 'eval_accuracy': 0.9287772087067862, 'eval_f1': 0.9303381340012523, 'eval_precision': 0.9101071975497703, 'eval_recall': 0.9514889529298751, 'eval_runtime': 34.2639, 'eval_samples_per_second': 364.816, 'eval_steps_per_second': 22.823, 'epoch': 9.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(enc_test)\n",
    "print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to ./results_20250318_021030/final_model\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "trainer.save_model(f\"{output_dir}/final_model\")\n",
    "print(f\"Final model saved to {output_dir}/final_model\")\n",
    "\n",
    "# Example of using the model for inference a new sentence\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probabilities, dim=-1).item()\n",
    "    confidence = probabilities[0][prediction].item()\n",
    "    \n",
    "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    return sentiment, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This movie was absolutely fantastic! I loved every minute of it.\n",
      "Sentiment: Positive (confidence: 0.9994)\n",
      "--------------------------------------------------\n",
      "Text: What a waste of time. Terrible acting and boring plot.\n",
      "Sentiment: Negative (confidence: 0.9998)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "        \"This movie was absolutely fantastic! I loved every minute of it.\",\n",
    "        \"What a waste of time. Terrible acting and boring plot.\"\n",
    "    ]\n",
    "for text in test_texts:\n",
    "        sentiment, confidence = predict_sentiment(text)\n",
    "        print(f\"Text: {text}\")\n",
    "        print(f\"Sentiment: {sentiment} (confidence: {confidence:.4f})\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
