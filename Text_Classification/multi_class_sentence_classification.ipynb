{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0- Fine-tuning BERT for multi-class classification with Turkish language datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import kagglehub\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast \n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Early stopping callback\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already there !\n",
      "data.shape=(4900, 2)\n"
     ]
    }
   ],
   "source": [
    "if \"TTC4900.csv\" not in os.listdir():\n",
    " !wget  https://raw.githubusercontent.com/savasy/TurkishTextClassification/master/TTC4900.csv\n",
    "else:\n",
    "   print(\"Already there !\")\n",
    "\n",
    "data= pd.read_csv(\"TTC4900.csv\")\n",
    "data=data.sample(frac=1.0, random_state=42)\n",
    "data.head(5)\n",
    "print(f\"data.shape={data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'teknoloji': 0, 'ekonomi': 1, 'saglik': 2, 'siyaset': 3, 'kultur': 4, 'spor': 5, 'dunya': 6}\n",
      "len(train_texts): 2450\n",
      "len(train_labels): 2450\n",
      "len(val_texts): 1225\n",
      "len(val_labels): 1225\n",
      "len(test_texts): 1225\n",
      "len(test_labels): 1225\n"
     ]
    }
   ],
   "source": [
    "labels=[\"teknoloji\",\"ekonomi\",\"saglik\",\"siyaset\",\"kultur\",\"spor\",\"dunya\"]\n",
    "NUM_LABELS= len(labels)\n",
    "id2label={i:l for i,l in enumerate(labels)}\n",
    "label2id={l:i for i,l in enumerate(labels)}\n",
    "print(f\"label2id: {label2id}\")\n",
    "# Convert the category labels to integers\n",
    "data[\"labels\"]=data.category.map(lambda x: label2id[x.strip()])\n",
    "data.head()\n",
    "\n",
    "SIZE= data.shape[0]\n",
    "\n",
    "train_texts= list(data.text[:SIZE//2])\n",
    "val_texts=   list(data.text[SIZE//2:(3*SIZE)//4 ])\n",
    "test_texts=  list(data.text[(3*SIZE)//4:])\n",
    "\n",
    "train_labels= list(data.labels[:SIZE//2])\n",
    "val_labels=   list(data.labels[SIZE//2:(3*SIZE)//4])\n",
    "test_labels=  list(data.labels[(3*SIZE)//4:])\n",
    "print(f\"len(train_texts): {len(train_texts)}\")\n",
    "print(f\"len(train_labels): {len(train_labels)}\")\n",
    "\n",
    "print(f\"len(val_texts): {len(val_texts)}\")  \n",
    "print(f\"len(val_labels): {len(val_labels)}\")\n",
    "\n",
    "print(f\"len(test_texts): {len(test_texts)}\")\n",
    "print(f\"len(test_labels): {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- call the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer= BertTokenizerFast.from_pretrained(\"dbmdz/bert-base-turkish-uncased\", max_length=512)\n",
    "model= BertForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-uncased\",\n",
    "                                                    num_labels=NUM_LABELS,\n",
    "                                                    id2label=id2label,\n",
    "                                                    label2id=label2id).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings  = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Create a customized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 2450\n",
      "Validation dataset length: 1225\n",
      "Test dataset length: 1225\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() if isinstance(val[idx], torch.Tensor) else torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MyDataset(train_encodings, train_labels)\n",
    "val_dataset = MyDataset(val_encodings, val_labels)\n",
    "test_dataset = MyDataset(test_encodings, test_labels)\n",
    "\n",
    "print(f\"Training dataset length: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset length: {len(val_dataset)}\")\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/v3/envs/text_classification/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "You are adding a <class 'transformers.integrations.integration_utils.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2295' max='2295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2295/2295 15:34, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.702300</td>\n",
       "      <td>0.689540</td>\n",
       "      <td>0.876645</td>\n",
       "      <td>0.873478</td>\n",
       "      <td>0.881566</td>\n",
       "      <td>0.876606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.299460</td>\n",
       "      <td>0.913651</td>\n",
       "      <td>0.912397</td>\n",
       "      <td>0.915028</td>\n",
       "      <td>0.914213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.303211</td>\n",
       "      <td>0.911184</td>\n",
       "      <td>0.911755</td>\n",
       "      <td>0.914564</td>\n",
       "      <td>0.910592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.359534</td>\n",
       "      <td>0.915296</td>\n",
       "      <td>0.914196</td>\n",
       "      <td>0.914351</td>\n",
       "      <td>0.915266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.435920</td>\n",
       "      <td>0.916118</td>\n",
       "      <td>0.916292</td>\n",
       "      <td>0.920918</td>\n",
       "      <td>0.915784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>0.917763</td>\n",
       "      <td>0.918180</td>\n",
       "      <td>0.918658</td>\n",
       "      <td>0.917916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.412446</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921368</td>\n",
       "      <td>0.921175</td>\n",
       "      <td>0.921865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.523684</td>\n",
       "      <td>0.908717</td>\n",
       "      <td>0.908764</td>\n",
       "      <td>0.912098</td>\n",
       "      <td>0.907818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.427018</td>\n",
       "      <td>0.929276</td>\n",
       "      <td>0.928722</td>\n",
       "      <td>0.929579</td>\n",
       "      <td>0.929022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.490762</td>\n",
       "      <td>0.917763</td>\n",
       "      <td>0.917476</td>\n",
       "      <td>0.919940</td>\n",
       "      <td>0.917303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.477713</td>\n",
       "      <td>0.925987</td>\n",
       "      <td>0.925432</td>\n",
       "      <td>0.925978</td>\n",
       "      <td>0.925470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.481768</td>\n",
       "      <td>0.926809</td>\n",
       "      <td>0.926382</td>\n",
       "      <td>0.926416</td>\n",
       "      <td>0.926490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.503584</td>\n",
       "      <td>0.923520</td>\n",
       "      <td>0.922978</td>\n",
       "      <td>0.923042</td>\n",
       "      <td>0.923322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.515324</td>\n",
       "      <td>0.925164</td>\n",
       "      <td>0.924582</td>\n",
       "      <td>0.924736</td>\n",
       "      <td>0.924950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.522008</td>\n",
       "      <td>0.925987</td>\n",
       "      <td>0.925495</td>\n",
       "      <td>0.925691</td>\n",
       "      <td>0.925791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.527197</td>\n",
       "      <td>0.925987</td>\n",
       "      <td>0.925495</td>\n",
       "      <td>0.925691</td>\n",
       "      <td>0.925791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.541359</td>\n",
       "      <td>0.919408</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>0.919983</td>\n",
       "      <td>0.918733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.547223</td>\n",
       "      <td>0.919408</td>\n",
       "      <td>0.919113</td>\n",
       "      <td>0.919982</td>\n",
       "      <td>0.918733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.546693</td>\n",
       "      <td>0.924342</td>\n",
       "      <td>0.924007</td>\n",
       "      <td>0.924491</td>\n",
       "      <td>0.923956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.548315</td>\n",
       "      <td>0.924342</td>\n",
       "      <td>0.923899</td>\n",
       "      <td>0.924371</td>\n",
       "      <td>0.923918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.549564</td>\n",
       "      <td>0.923520</td>\n",
       "      <td>0.923031</td>\n",
       "      <td>0.923435</td>\n",
       "      <td>0.923120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.550709</td>\n",
       "      <td>0.924342</td>\n",
       "      <td>0.923899</td>\n",
       "      <td>0.924371</td>\n",
       "      <td>0.923918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the best model at ./multi_class_results_20250319_151639/checkpoint-900/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "TrainOutput(global_step=2295, training_loss=0.1259467977291878, metrics={'train_runtime': 935.4611, 'train_samples_per_second': 39.285, 'train_steps_per_second': 2.453, 'total_flos': 9661871683584000.0, 'train_loss': 0.1259467977291878, 'epoch': 15.0})\n"
     ]
    }
   ],
   "source": [
    "# Create output directories\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f'./multi_class_results_{timestamp}'\n",
    "log_dir = f'./multi_class_logs_{timestamp}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to calculate the metrics\n",
    "\n",
    "def compute_metrics(pred): \n",
    "    labels = pred.label_ids \n",
    "    preds = pred.predictions.argmax(-1) \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro') \n",
    "    acc = accuracy_score(labels, preds) \n",
    "    return { \n",
    "        'accuracy': acc, \n",
    "        'f1': f1, \n",
    "        'precision': precision, \n",
    "        'recall': recall \n",
    "    } \n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # output directory for model predictions and checkpoints\n",
    "    do_eval=True,  # whether to evaluate during training\n",
    "    do_train=True,  # whether to train the model\n",
    "    num_train_epochs=15,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # reduced batch size to prevent CUDA OOM errors\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    warmup_ratio=0.1,  # ratio of warmup steps - more flexible than fixed steps\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=log_dir,  # directory to save logs\n",
    "    save_strategy='steps',  # save the model after each epoch\n",
    "    evaluation_strategy='steps',  # evaluate the model after each epoch\n",
    "    logging_strategy='steps',  # log steps instead of epochs for more frequent updates\n",
    "    report_to='tensorboard',  # report logs to TensorBoard\n",
    "    logging_steps=100,  # how often to log the training loss\n",
    "    fp16=True if torch.cuda.is_available() else False,  # whether to use mixed precision training\n",
    "    load_best_model_at_end=True,  # load the best model when finished training\n",
    "    metric_for_best_model='f1',  # use F1 score to determine best model\n",
    "    greater_is_better=True,  # higher F1 is better\n",
    "    seed=seed,\n",
    "    dataloader_drop_last=True,  # drop last incomplete batch\n",
    "    save_total_limit=3,  # limit the total amount of checkpoints saved\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    # the pre-trained model that will be fine-tuned \n",
    "    model=model,\n",
    "     # training arguments that we defined above                        \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    compute_metrics= compute_metrics,\n",
    "    callbacks=[\n",
    "        TensorBoardCallback()\n",
    "    ]\n",
    ")\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "results = trainer.train()\n",
    "print(\"Training completed!\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.4788854420185089, 'eval_accuracy': 0.9317434210526315, 'eval_f1': 0.9307383996879516, 'eval_precision': 0.9305816365878795, 'eval_recall': 0.9312659470697292, 'eval_runtime': 6.5906, 'eval_samples_per_second': 185.872, 'eval_steps_per_second': 11.683, 'epoch': 15.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Save the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to ./multi_class_results_20250319_151639/final_multi_class_model\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "trainer.save_model(f\"{output_dir}/final_multi_class_model\")\n",
    "print(f\"Final model saved to {output_dir}/final_multi_class_model\")\n",
    "\n",
    "# Example of using the model for inference a new sentence\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probabilities, dim=-1).item()\n",
    "    \n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8- Run the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: FenerbahÃ§eli futbolcular kÄ±sa paslarla hazÄ±rlÄ±k Ã§alÄ±ÅŸmasÄ± yaptÄ±lar\n",
      "Prediction: spor  -  True label: spor\n",
      "--------------------------------------------------\n",
      "Text: TÃ¼rkiyeâ€™de mali istikrarÄ± saÄŸlamak ve yatÄ±rÄ±mlarÄ± artÄ±rmak iÃ§in yeni politikalar geliÅŸtirilmelidir.\n",
      "Prediction: ekonomi  -  True label: ekonomi\n",
      "--------------------------------------------------\n",
      "Text: Yapay zeka ve otomasyon, Ã¼retim sektÃ¶rÃ¼nde verimliliÄŸi artÄ±rarak maliyetleri dÃ¼ÅŸÃ¼rÃ¼yor.\n",
      "Prediction: teknoloji  -  True label: teknoloji\n",
      "--------------------------------------------------\n",
      "Text: KÃ¼resel Ä±sÄ±nma, dÃ¼nyanÄ±n ekosistemlerini ve iklim dengesini tehdit eden en bÃ¼yÃ¼k sorunlardan biridir.\n",
      "Prediction: teknoloji  -  True label: dunya\n",
      "--------------------------------------------------\n",
      "Text: KoronavirÃ¼s salgÄ±nÄ±nda gÃ¼nlÃ¼k vaka sayÄ±sÄ± 50.000'in Ã¼zerine Ã§Ä±ktÄ±.\n",
      "Prediction: saglik  -  True label: saglik\n",
      "--------------------------------------------------\n",
      "Text: TÃ¼rkiye'nin en bÃ¼yÃ¼k sorunu olan terÃ¶r, son yÄ±llarda bÃ¼yÃ¼k oranda azaldÄ±.\n",
      "Prediction: siyaset  -  True label: siyaset\n",
      "--------------------------------------------------\n",
      "Text: TÃ¼rkiye'nin kÃ¼ltÃ¼rel zenginlikleri, dÃ¼nya genelinde bÃ¼yÃ¼k ilgi gÃ¶rÃ¼yor.\n",
      "Prediction: kultur  -  True label: kultur\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "        \"FenerbahÃ§eli futbolcular kÄ±sa paslarla hazÄ±rlÄ±k Ã§alÄ±ÅŸmasÄ± yaptÄ±lar\", # spor\n",
    "        \"TÃ¼rkiyeâ€™de mali istikrarÄ± saÄŸlamak ve yatÄ±rÄ±mlarÄ± artÄ±rmak iÃ§in yeni politikalar geliÅŸtirilmelidir.\", # ekonomi\n",
    "        \"Yapay zeka ve otomasyon, Ã¼retim sektÃ¶rÃ¼nde verimliliÄŸi artÄ±rarak maliyetleri dÃ¼ÅŸÃ¼rÃ¼yor.\", # teknoloji\n",
    "        \"KÃ¼resel Ä±sÄ±nma, dÃ¼nyanÄ±n ekosistemlerini ve iklim dengesini tehdit eden en bÃ¼yÃ¼k sorunlardan biridir.\", # dÃ¼nya\n",
    "        \"KoronavirÃ¼s salgÄ±nÄ±nda gÃ¼nlÃ¼k vaka sayÄ±sÄ± 50.000'in Ã¼zerine Ã§Ä±ktÄ±.\", # saÄŸlÄ±k\n",
    "        \"TÃ¼rkiye'nin en bÃ¼yÃ¼k sorunu olan terÃ¶r, son yÄ±llarda bÃ¼yÃ¼k oranda azaldÄ±.\", # siyaset\n",
    "        \"TÃ¼rkiye'nin kÃ¼ltÃ¼rel zenginlikleri, dÃ¼nya genelinde bÃ¼yÃ¼k ilgi gÃ¶rÃ¼yor.\" # kÃ¼ltÃ¼r\n",
    "    ]\n",
    "test_texts_labels = [\"spor\", \"ekonomi\", \"teknoloji\", \"dunya\", \"saglik\", \"siyaset\", \"kultur\"]\n",
    "\n",
    "\n",
    "for index, text in enumerate(test_texts):\n",
    "    prediction = predict_sentiment(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {prediction}  -  True label: {test_texts_labels[index]}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
