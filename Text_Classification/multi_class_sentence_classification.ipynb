{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0- Fine-tuning BERT for multi-class classification with Turkish language datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import kagglehub\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast \n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Early stopping callback\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/saeid/.cache/kagglehub/datasets/savasy/ttc4900/versions/3\n",
      "   category                                               text\n",
      "0  siyaset    3 milyon ile ön seçim vaadi mhp nin 10 olağan...\n",
      "1  siyaset    mesut_yılmaz yüce_divan da ceza alabilirdi pr...\n",
      "2  siyaset    disko lar kaldırılıyor başbakan_yardımcısı ar...\n",
      "3  siyaset    sarıgül anayasa_mahkemesi ne gidiyor mustafa_...\n",
      "4  siyaset    erdoğan idamın bir haklılık sebebi var demek ...\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"savasy/ttc4900\")\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "csv_file = os.path.join(dataset_path, \"7allV03.csv\")\n",
    "\n",
    "# Load the CSV into a pandas DataFrame\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"teknoloji\", \"ekonomi\", \"saglik\", \"siyaset\", \"kultur\", \"spor\", \"dunya\"]\n",
    "Num_labels= len(labels)\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "# Divide the dataset into training, validation, and test sets\n",
    "size_data = data.shape[0] \n",
    "# text Data\n",
    "train_texts = data[\"text\"][:int(size_data*0.5)].tolist()\n",
    "val_texts= data[\"text\"][int(size_data*0.5):int(size_data*0.75)].tolist()\n",
    "test_texts = data[\"text\"][int(size_data*0.75):].tolist()\n",
    "# Label Data \n",
    "train_labels= data[\"category\"][:int(size_data*0.5)].tolist()\n",
    "val_labels= data[\"category\"][int(size_data*0.5):int(size_data*0.75)].tolist()\n",
    "test_labels= data[\"category\"][int(size_data*0.75):].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- call the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer= BertTokenizerFast.from_pretrained(\"dbmdz/bert-base-turkish-uncased\", max_length=512)\n",
    "model= BertForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-uncased\",\n",
    "                                                    num_labels=Num_labels,\n",
    "                                                    id2label=id2label,\n",
    "                                                    label2id=label2id).to(device)\n",
    "print(f\"len(train_texts): {len(train_texts)}\")\n",
    "print(f\"len(train_labels): {len(train_labels)}\")\n",
    "\n",
    "print(f\"len(val_texts): {len(val_texts)}\")  \n",
    "print(f\"len(val_labels): {len(val_labels)}\")\n",
    "\n",
    "print(f\"len(test_texts): {len(test_texts)}\")\n",
    "print(f\"len(test_labels): {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train= tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "enc_val= tokenizer(val_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "enc_test= tokenizer(test_texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Create a customized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset=MyDataset(enc_train, train_labels)\n",
    "val_dataset=MyDataset(enc_val, val_labels)\n",
    "test_dataset=MyDataset(enc_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f'./multi_class_results_{timestamp}'\n",
    "log_dir = f'./multi_class_logs_{timestamp}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Function to calculate the metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # output directory for model predictions and checkpoints\n",
    "    num_train_epochs=10,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # reduced batch size to prevent CUDA OOM errors\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    warmup_ratio=0.1,  # ratio of warmup steps - more flexible than fixed steps\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=log_dir,  # directory to save logs\n",
    "    do_eval=True,  # whether to evaluate during training\n",
    "    do_train=True,  # whether to train the model\n",
    "    save_strategy='epoch',  # save the model after each epoch\n",
    "    evaluation_strategy='epoch',  # evaluate the model after each epoch\n",
    "    logging_strategy='steps',  # log steps instead of epochs for more frequent updates\n",
    "    report_to='tensorboard',  # report logs to TensorBoard\n",
    "    logging_steps=100,  # how often to log the training loss\n",
    "    fp16=True if torch.cuda.is_available() else False,  # whether to use mixed precision training\n",
    "    load_best_model_at_end=True,  # load the best model when finished training\n",
    "    metric_for_best_model='f1',  # use F1 score to determine best model\n",
    "    greater_is_better=True,  # higher F1 is better\n",
    "    seed=seed,\n",
    "    dataloader_drop_last=True,  # drop last incomplete batch\n",
    "    gradient_accumulation_steps=2,  # accumulate gradients for effective larger batch size\n",
    "    save_total_limit=1,  # limit the total amount of checkpoints saved\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=enc_train,\n",
    "    eval_dataset=enc_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=3),\n",
    "        TensorBoardCallback()\n",
    "    ]\n",
    ")\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "results = trainer.train()\n",
    "print(\"Training completed!\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(enc_test)\n",
    "print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Save the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "trainer.save_model(f\"{output_dir}/final_multi_class_model\")\n",
    "print(f\"Final model saved to {output_dir}/final_multi_class_model\")\n",
    "\n",
    "# Example of using the model for inference a new sentence\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probabilities, dim=-1).item()\n",
    "    confidence = probabilities[0][prediction].item()\n",
    "    \n",
    "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    return sentiment, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8- Run the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "        \"Fenerbahçeli futbolcular kısa paslarla hazırlık çalışması yaptılar\",\n",
    "        \"Türkiye’de mali istikrarı sağlamak ve yatırımları artırmak için yeni politikalar geliştirilmelidir.\",\n",
    "        \"Yapay zeka ve otomasyon, üretim sektöründe verimliliği artırarak maliyetleri düşürüyor.\",\n",
    "        \"Küresel ısınma, dünyanın ekosistemlerini ve iklim dengesini tehdit eden en büyük sorunlardan biridir.\",\n",
    "    ]\n",
    "for text in test_texts:\n",
    "        sentiment, confidence = predict_sentiment(text)\n",
    "        print(f\"Text: {text}\")\n",
    "        print(f\"Sentiment: {sentiment} (confidence: {confidence:.4f})\")\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
