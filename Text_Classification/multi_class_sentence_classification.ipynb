{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0- Fine-tuning BERT for multi-class classification with Turkish language datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import kagglehub\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast \n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Early stopping callback\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"TTC4900.csv\" not in os.listdir():\n",
    " !wget  https://raw.githubusercontent.com/savasy/TurkishTextClassification/master/TTC4900.csv\n",
    "else:\n",
    "   print(\"Already there !\")\n",
    "\n",
    "data= pd.read_csv(\"TTC4900.csv\")\n",
    "data=data.sample(frac=1.0, random_state=42)\n",
    "data.head(5)\n",
    "print(f\"data.shape={data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"teknoloji\",\"ekonomi\",\"sağlık\",\"siyaset\",\"kültür\",\"spor\",\"dünya\"]\n",
    "NUM_LABELS= len(labels)\n",
    "id2label={i:l for i,l in enumerate(labels)}\n",
    "label2id={l:i for i,l in enumerate(labels)}\n",
    "print(f\"label2id: {label2id}\")\n",
    "# Convert the category labels to integers\n",
    "data[\"labels\"]=data.category.map(lambda x: label2id[x.strip()])\n",
    "data.head()\n",
    "\n",
    "SIZE= data.shape[0]\n",
    "\n",
    "train_texts= list(data.text[:SIZE//2])\n",
    "val_texts=   list(data.text[SIZE//2:(3*SIZE)//4 ])\n",
    "test_texts=  list(data.text[(3*SIZE)//4:])\n",
    "\n",
    "train_labels= list(data.labels[:SIZE//2])\n",
    "val_labels=   list(data.labels[SIZE//2:(3*SIZE)//4])\n",
    "test_labels=  list(data.labels[(3*SIZE)//4:])\n",
    "print(f\"len(train_texts): {len(train_texts)}\")\n",
    "print(f\"len(train_labels): {len(train_labels)}\")\n",
    "\n",
    "print(f\"len(val_texts): {len(val_texts)}\")  \n",
    "print(f\"len(val_labels): {len(val_labels)}\")\n",
    "\n",
    "print(f\"len(test_texts): {len(test_texts)}\")\n",
    "print(f\"len(test_labels): {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- call the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer= BertTokenizerFast.from_pretrained(\"dbmdz/bert-base-turkish-uncased\", max_length=512)\n",
    "model= BertForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-uncased\",\n",
    "                                                    num_labels=NUM_LABELS,\n",
    "                                                    id2label=id2label,\n",
    "                                                    label2id=label2id).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings  = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Create a customized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() if isinstance(val[idx], torch.Tensor) else torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MyDataset(train_encodings, train_labels)\n",
    "val_dataset = MyDataset(val_encodings, val_labels)\n",
    "test_dataset = MyDataset(test_encodings, test_labels)\n",
    "\n",
    "print(f\"Training dataset length: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset length: {len(val_dataset)}\")\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f'./multi_class_results_{timestamp}'\n",
    "log_dir = f'./multi_class_logs_{timestamp}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to calculate the metrics\n",
    "\n",
    "def compute_metrics(pred): \n",
    "    labels = pred.label_ids \n",
    "    preds = pred.predictions.argmax(-1) \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro') \n",
    "    acc = accuracy_score(labels, preds) \n",
    "    return { \n",
    "        'accuracy': acc, \n",
    "        'f1': f1, \n",
    "        'precision': precision, \n",
    "        'recall': recall \n",
    "    } \n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,  # output directory for model predictions and checkpoints\n",
    "    do_eval=True,  # whether to evaluate during training\n",
    "    do_train=True,  # whether to train the model\n",
    "    num_train_epochs=15,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # reduced batch size to prevent CUDA OOM errors\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    warmup_ratio=0.1,  # ratio of warmup steps - more flexible than fixed steps\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=log_dir,  # directory to save logs\n",
    "    save_strategy='steps',  # save the model after each epoch\n",
    "    evaluation_strategy='steps',  # evaluate the model after each epoch\n",
    "    logging_strategy='steps',  # log steps instead of epochs for more frequent updates\n",
    "    report_to='tensorboard',  # report logs to TensorBoard\n",
    "    logging_steps=100,  # how often to log the training loss\n",
    "    fp16=True if torch.cuda.is_available() else False,  # whether to use mixed precision training\n",
    "    load_best_model_at_end=True,  # load the best model when finished training\n",
    "    metric_for_best_model='f1',  # use F1 score to determine best model\n",
    "    greater_is_better=True,  # higher F1 is better\n",
    "    seed=seed,\n",
    "    dataloader_drop_last=True,  # drop last incomplete batch\n",
    "    save_total_limit=3,  # limit the total amount of checkpoints saved\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    # the pre-trained model that will be fine-tuned \n",
    "    model=model,\n",
    "     # training arguments that we defined above                        \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    compute_metrics= compute_metrics,\n",
    "    callbacks=[\n",
    "        TensorBoardCallback()\n",
    "    ]\n",
    ")\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "results = trainer.train()\n",
    "print(\"Training completed!\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Save the final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "trainer.save_model(f\"{output_dir}/final_multi_class_model\")\n",
    "print(f\"Final model saved to {output_dir}/final_multi_class_model\")\n",
    "\n",
    "# Example of using the model for inference a new sentence\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probabilities, dim=-1).item()\n",
    "    \n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8- Run the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "        \"Fenerbahçeli futbolcular kısa paslarla hazırlık çalışması yaptılar\", # spor\n",
    "        \"Türkiye’de mali istikrarı sağlamak ve yatırımları artırmak için yeni politikalar geliştirilmelidir.\", # ekonomi\n",
    "        \"Yapay zeka ve otomasyon, üretim sektöründe verimliliği artırarak maliyetleri düşürüyor.\", # teknoloji\n",
    "        \"Küresel ısınma, dünyanın ekosistemlerini ve iklim dengesini tehdit eden en büyük sorunlardan biridir.\", # dünya\n",
    "        \"Koronavirüs salgınında günlük vaka sayısı 50.000'in üzerine çıktı.\", # sağlık\n",
    "        \"Türkiye'nin en büyük sorunu olan terör, son yıllarda büyük oranda azaldı.\", # siyaset\n",
    "        \"Türkiye'nin kültürel zenginlikleri, dünya genelinde büyük ilgi görüyor.\" # kültür\n",
    "    ]\n",
    "test_texts_labels = [\"spor\", \"ekonomi\", \"teknoloji\", \"dünya\", \"sağlık\", \"siyaset\", \"kültür\"]\n",
    "for index, text in enumerate(test_texts):\n",
    "    prediction = predict_sentiment(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {prediction}  -  True label: {test_texts_labels[index]}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
