{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/v3/envs/text_classification/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from torch.cuda.amp import autocast\n",
    "from datasets import load_dataset \n",
    "from datasets import Dataset \n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from transformers import AutoTokenizer, XLNetForSequenceClassification, DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "# AutoTokenizer : Automatically loads the appropriate tokenizer for a given pre-trained model.\n",
    "# AutoModelForSequenceClassification:  Loads a pre-trained transformer model for sequence classification tasks (e.g., sentiment analysis, spam detection, etc.)\n",
    "# XLNetTokenizer : Loads the XLNet tokenizer\n",
    "# XLNetForSequenceClassification : Loads the XLNet model for sequence classification\n",
    "# TrainingArguments: Contains all the hyperparameters needed for training a model\n",
    "# Trainer: A high-level interface for training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Load Dataset\n",
    "The dataset is downlaoded form this page:\n",
    "\n",
    "https://huggingface.co/owaiskha9654/Multi-Label-Classification-of-PubMed-Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>meshMajor</th>\n",
       "      <th>pmid</th>\n",
       "      <th>meshid</th>\n",
       "      <th>meshroot</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expression of p53 and coexistence of HPV in pr...</td>\n",
       "      <td>Fifty-four paraffin embedded tissue sections f...</td>\n",
       "      <td>['DNA Probes, HPV', 'DNA, Viral', 'Female', 'H...</td>\n",
       "      <td>8549602</td>\n",
       "      <td>[['D13.444.600.223.555', 'D27.505.259.750.600....</td>\n",
       "      <td>['Chemicals and Drugs [D]', 'Organisms [B]', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vitamin D status in pregnant Indian women acro...</td>\n",
       "      <td>The present cross-sectional study was conducte...</td>\n",
       "      <td>['Adult', 'Alkaline Phosphatase', 'Breast Feed...</td>\n",
       "      <td>21736816</td>\n",
       "      <td>[['M01.060.116'], ['D08.811.277.352.650.035'],...</td>\n",
       "      <td>['Named Groups [M]', 'Chemicals and Drugs [D]'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Identification of a functionally important di...</td>\n",
       "      <td>The occurrence of individual amino acids and d...</td>\n",
       "      <td>['Amino Acid Sequence', 'Analgesics, Opioid', ...</td>\n",
       "      <td>19060934</td>\n",
       "      <td>[['G02.111.570.060', 'L01.453.245.667.060'], [...</td>\n",
       "      <td>['Phenomena and Processes [G]', 'Information S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multilayer capsules: a promising microencapsul...</td>\n",
       "      <td>In 1980, Lim and Sun introduced a microcapsule...</td>\n",
       "      <td>['Acrylic Resins', 'Alginates', 'Animals', 'Bi...</td>\n",
       "      <td>11426874</td>\n",
       "      <td>[['D05.750.716.822.111', 'D25.720.716.822.111'...</td>\n",
       "      <td>['Chemicals and Drugs [D]', 'Technology, Indus...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nanohydrogel with N,N'-bis(acryloyl)cystine cr...</td>\n",
       "      <td>Substantially improved hydrogel particles base...</td>\n",
       "      <td>['Antineoplastic Agents', 'Cell Proliferation'...</td>\n",
       "      <td>28323099</td>\n",
       "      <td>[['D27.505.954.248'], ['G04.161.750', 'G07.345...</td>\n",
       "      <td>['Chemicals and Drugs [D]', 'Phenomena and Pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Five donors-one recipient: modeling a mosaic o...</td>\n",
       "      <td>BACKGROUND: A 21-year-old man was admitted to ...</td>\n",
       "      <td>['Adult', 'Cell Transplantation', 'Cord Blood ...</td>\n",
       "      <td>18364724</td>\n",
       "      <td>[['M01.060.116'], ['E02.095.147.500', 'E04.936...</td>\n",
       "      <td>['Named Groups [M]', 'Analytical, Diagnostic a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The role of eicosanoids in cyclosporine nephro...</td>\n",
       "      <td>Nephrotoxicity is the most troublesome complic...</td>\n",
       "      <td>['Animals', 'Cyclosporins', 'In Vitro Techniqu...</td>\n",
       "      <td>2735953</td>\n",
       "      <td>[['B01.050'], ['D04.345.566.235', 'D12.644.641...</td>\n",
       "      <td>['Organisms [B]', 'Chemicals and Drugs [D]', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Impact of pancreaticoduodenal arcade dilation ...</td>\n",
       "      <td>BACKGROUND: The aim of this study was to inves...</td>\n",
       "      <td>['Adult', 'Aged', 'Aged, 80 and over', 'Dilata...</td>\n",
       "      <td>28919282</td>\n",
       "      <td>[['M01.060.116'], ['M01.060.116.100'], ['M01.0...</td>\n",
       "      <td>['Named Groups [M]', 'Diseases [C]', 'Anatomy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Outcomes of Preterm Infants following Discussi...</td>\n",
       "      <td>OBJECTIVES: To describe the frequency of postn...</td>\n",
       "      <td>['Decision Making', 'Female', 'Humans', 'Infan...</td>\n",
       "      <td>28647272</td>\n",
       "      <td>[['F02.463.785.373'], ['B01.050.150.900.649.31...</td>\n",
       "      <td>['Psychiatry and Psychology [F]', 'Organisms [...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Molecular subtyping of Borrelia burgdorferi se...</td>\n",
       "      <td>Solitary lymphocytoma is a rare cutaneous mani...</td>\n",
       "      <td>['Adult', 'Aged', 'Antigens, Surface', 'Bacter...</td>\n",
       "      <td>8980295</td>\n",
       "      <td>[['M01.060.116'], ['M01.060.116.100'], ['D23.0...</td>\n",
       "      <td>['Named Groups [M]', 'Chemicals and Drugs [D]'...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "0      Expression of p53 and coexistence of HPV in pr...   \n",
       "1      Vitamin D status in pregnant Indian women acro...   \n",
       "2      [Identification of a functionally important di...   \n",
       "3      Multilayer capsules: a promising microencapsul...   \n",
       "4      Nanohydrogel with N,N'-bis(acryloyl)cystine cr...   \n",
       "...                                                  ...   \n",
       "49995  Five donors-one recipient: modeling a mosaic o...   \n",
       "49996  The role of eicosanoids in cyclosporine nephro...   \n",
       "49997  Impact of pancreaticoduodenal arcade dilation ...   \n",
       "49998  Outcomes of Preterm Infants following Discussi...   \n",
       "49999  Molecular subtyping of Borrelia burgdorferi se...   \n",
       "\n",
       "                                            abstractText  \\\n",
       "0      Fifty-four paraffin embedded tissue sections f...   \n",
       "1      The present cross-sectional study was conducte...   \n",
       "2      The occurrence of individual amino acids and d...   \n",
       "3      In 1980, Lim and Sun introduced a microcapsule...   \n",
       "4      Substantially improved hydrogel particles base...   \n",
       "...                                                  ...   \n",
       "49995  BACKGROUND: A 21-year-old man was admitted to ...   \n",
       "49996  Nephrotoxicity is the most troublesome complic...   \n",
       "49997  BACKGROUND: The aim of this study was to inves...   \n",
       "49998  OBJECTIVES: To describe the frequency of postn...   \n",
       "49999  Solitary lymphocytoma is a rare cutaneous mani...   \n",
       "\n",
       "                                               meshMajor      pmid  \\\n",
       "0      ['DNA Probes, HPV', 'DNA, Viral', 'Female', 'H...   8549602   \n",
       "1      ['Adult', 'Alkaline Phosphatase', 'Breast Feed...  21736816   \n",
       "2      ['Amino Acid Sequence', 'Analgesics, Opioid', ...  19060934   \n",
       "3      ['Acrylic Resins', 'Alginates', 'Animals', 'Bi...  11426874   \n",
       "4      ['Antineoplastic Agents', 'Cell Proliferation'...  28323099   \n",
       "...                                                  ...       ...   \n",
       "49995  ['Adult', 'Cell Transplantation', 'Cord Blood ...  18364724   \n",
       "49996  ['Animals', 'Cyclosporins', 'In Vitro Techniqu...   2735953   \n",
       "49997  ['Adult', 'Aged', 'Aged, 80 and over', 'Dilata...  28919282   \n",
       "49998  ['Decision Making', 'Female', 'Humans', 'Infan...  28647272   \n",
       "49999  ['Adult', 'Aged', 'Antigens, Surface', 'Bacter...   8980295   \n",
       "\n",
       "                                                  meshid  \\\n",
       "0      [['D13.444.600.223.555', 'D27.505.259.750.600....   \n",
       "1      [['M01.060.116'], ['D08.811.277.352.650.035'],...   \n",
       "2      [['G02.111.570.060', 'L01.453.245.667.060'], [...   \n",
       "3      [['D05.750.716.822.111', 'D25.720.716.822.111'...   \n",
       "4      [['D27.505.954.248'], ['G04.161.750', 'G07.345...   \n",
       "...                                                  ...   \n",
       "49995  [['M01.060.116'], ['E02.095.147.500', 'E04.936...   \n",
       "49996  [['B01.050'], ['D04.345.566.235', 'D12.644.641...   \n",
       "49997  [['M01.060.116'], ['M01.060.116.100'], ['M01.0...   \n",
       "49998  [['F02.463.785.373'], ['B01.050.150.900.649.31...   \n",
       "49999  [['M01.060.116'], ['M01.060.116.100'], ['D23.0...   \n",
       "\n",
       "                                                meshroot  A  B  C  D  E  F  G  \\\n",
       "0      ['Chemicals and Drugs [D]', 'Organisms [B]', '...  0  1  1  1  1  0  0   \n",
       "1      ['Named Groups [M]', 'Chemicals and Drugs [D]'...  0  1  1  1  1  1  1   \n",
       "2      ['Phenomena and Processes [G]', 'Information S...  1  1  0  1  1  0  1   \n",
       "3      ['Chemicals and Drugs [D]', 'Technology, Indus...  1  1  1  1  1  0  1   \n",
       "4      ['Chemicals and Drugs [D]', 'Phenomena and Pro...  1  1  0  1  1  0  1   \n",
       "...                                                  ... .. .. .. .. .. .. ..   \n",
       "49995  ['Named Groups [M]', 'Analytical, Diagnostic a...  1  1  1  0  1  0  1   \n",
       "49996  ['Organisms [B]', 'Chemicals and Drugs [D]', '...  1  1  0  1  1  0  0   \n",
       "49997  ['Named Groups [M]', 'Diseases [C]', 'Anatomy ...  1  1  1  0  1  0  0   \n",
       "49998  ['Psychiatry and Psychology [F]', 'Organisms [...  0  1  0  0  1  1  0   \n",
       "49999  ['Named Groups [M]', 'Chemicals and Drugs [D]'...  1  1  1  1  1  0  1   \n",
       "\n",
       "       H  I  J  L  M  N  Z  \n",
       "0      1  0  0  0  0  0  0  \n",
       "1      0  1  1  0  1  1  1  \n",
       "2      0  0  0  1  0  0  0  \n",
       "3      0  0  1  0  0  0  0  \n",
       "4      0  0  1  0  0  0  0  \n",
       "...   .. .. .. .. .. .. ..  \n",
       "49995  0  0  0  0  1  0  0  \n",
       "49996  0  0  0  0  0  0  0  \n",
       "49997  0  0  0  0  1  1  0  \n",
       "49998  1  0  0  0  1  1  0  \n",
       "49999  0  0  0  0  1  0  1  \n",
       "\n",
       "[50000 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"owaiskha9654/PubMed_MultiLabel_Text_Classification_Dataset_MeSH\"\n",
    "dataset = load_dataset(path, split = 'train')\n",
    "dataset= pd.DataFrame(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'Z']\n",
      "Number of labels: 14\n",
      "                                        abstractText  A  B  C  D  E  F  G  H  \\\n",
      "0  Fifty-four paraffin embedded tissue sections f...  0  1  1  1  1  0  0  1   \n",
      "1  The present cross-sectional study was conducte...  0  1  1  1  1  1  1  0   \n",
      "2  The occurrence of individual amino acids and d...  1  1  0  1  1  0  1  0   \n",
      "3  In 1980, Lim and Sun introduced a microcapsule...  1  1  1  1  1  0  1  0   \n",
      "4  Substantially improved hydrogel particles base...  1  1  0  1  1  0  1  0   \n",
      "\n",
      "   I  J  L  M  N  Z  \n",
      "0  0  0  0  0  0  0  \n",
      "1  1  1  0  1  1  1  \n",
      "2  0  0  1  0  0  0  \n",
      "3  0  1  0  0  0  0  \n",
      "4  0  1  0  0  0  0  \n"
     ]
    }
   ],
   "source": [
    "text_col = 'abstractText'\n",
    "label_names = list(dataset.columns[6:])\n",
    "dataset = dataset[[text_col]+ label_names ]\n",
    "num_labels = len(label_names) \n",
    "print(f\"Label names: {label_names}\")\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_487926/2723422202.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"labels\"] = dataset[label_names].apply(lambda x: list(x), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstractText</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fifty-four paraffin embedded tissue sections f...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The present cross-sectional study was conducte...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The occurrence of individual amino acids and d...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1980, Lim and Sun introduced a microcapsule...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Substantially improved hydrogel particles base...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>BACKGROUND: A 21-year-old man was admitted to ...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Nephrotoxicity is the most troublesome complic...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>BACKGROUND: The aim of this study was to inves...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>OBJECTIVES: To describe the frequency of postn...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Solitary lymphocytoma is a rare cutaneous mani...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstractText  \\\n",
       "0      Fifty-four paraffin embedded tissue sections f...   \n",
       "1      The present cross-sectional study was conducte...   \n",
       "2      The occurrence of individual amino acids and d...   \n",
       "3      In 1980, Lim and Sun introduced a microcapsule...   \n",
       "4      Substantially improved hydrogel particles base...   \n",
       "...                                                  ...   \n",
       "49995  BACKGROUND: A 21-year-old man was admitted to ...   \n",
       "49996  Nephrotoxicity is the most troublesome complic...   \n",
       "49997  BACKGROUND: The aim of this study was to inves...   \n",
       "49998  OBJECTIVES: To describe the frequency of postn...   \n",
       "49999  Solitary lymphocytoma is a rare cutaneous mani...   \n",
       "\n",
       "                                           labels  \n",
       "0      [0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "1      [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]  \n",
       "2      [1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]  \n",
       "3      [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]  \n",
       "4      [1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]  \n",
       "...                                           ...  \n",
       "49995  [1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "49996  [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "49997  [1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "49998  [0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0]  \n",
       "49999  [1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1]  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the labels to a list of integers\n",
    "dataset[\"labels\"] = dataset[label_names].apply(lambda x: list(x), axis=1)\n",
    "# drop the label columns\n",
    "dataset = dataset.drop(columns=label_names)\n",
    "dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into train (50%), val (25%), and test(25%) sets \n",
    "#copy_dataset = dataset.copy()\n",
    "train_samples_numbers = int(dataset.shape[0]*0.5)\n",
    "val_samples_numbers = int(dataset.shape[0]*0.75)\n",
    "\n",
    "train_df = dataset[:train_samples_numbers] \n",
    "val_df = dataset[train_samples_numbers:val_samples_numbers]\n",
    "test_df = dataset[val_samples_numbers:]\n",
    "\n",
    "# Dataset.from_pandas is a method from the Hugging Face datasets library, used to convert a Pandas DataFrame into a Dataset object\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Fine-tune XLNet model and its tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:04<00:00, 5496.39 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12500/12500 [00:02<00:00, 5622.37 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12500/12500 [00:02<00:00, 5522.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenizing(batched_text):\n",
    "    return tokenizer(batched_text[text_col], padding = 'max_length', truncation = True)\n",
    "\n",
    "# pre_train_weights = 'xlnet-base-cased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(pre_train_weights)\n",
    "# model = XLNetForSequenceClassification.from_pretrained(pre_train_weights, num_labels=num_labels)\n",
    "\n",
    "pretrain_model = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(pretrain_model, num_labels=num_labels)\n",
    "\n",
    "# tokenize the datasets, convert text into tokens\n",
    "train_encoded = train_dataset.map(tokenizing, batched=True, batch_size=100)\n",
    "val_encoded = val_dataset.map(tokenizing, batched=True, batch_size=100)\n",
    "test_encoded = test_dataset.map(tokenizing, batched=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    y_pred, y_true = pred\n",
    "    y_pred =torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    y_pred = y_pred.sigmoid()>0.5\n",
    "    y_true= y_true.bool()\n",
    "    precision= recall_score(y_true, y_pred, average='micro', pos_label=1)\n",
    "    precision= precision_score(y_true, y_pred, average='micro', pos_label=1)\n",
    "    f1= f1_score(y_true, y_pred, average='micro', pos_label=1)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': precision\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - For single-label multi-class classification, we use softmax activation followed by a cross-entropy loss function.\n",
    "\n",
    "### - However, for multi-label mode, we need to use different activation and loss fucntion.\n",
    "\n",
    "### - We use torch.n.BCEWithLogitsLoss() instead of torch.nn.CrossEntropyLoss()\n",
    "\n",
    "### - BCEWithLogitsLoss() is a loss function in PyTorch that combines binary cross-entropy (BCE) loss with a sigmoid activation function. It is commonly used for binary classification tasks and multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop('labels')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        preds_ = logits.view(-1, self.model.config.num_labels)\n",
    "        labels_ = labels.float().view(-1, self.model.config.num_labels)\n",
    "        loss = loss_fct(preds_, labels_)\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/v3/envs/text_classification/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', # output directory for model predictions and checkpoints\n",
    "    num_train_epochs=30,  # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # reduced batch size to prevent CUDA OOM errors\n",
    "    per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "    warmup_ratio=0.1,  # ratio of warmup steps - more flexible than fixed steps\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs', # directory to save logs\n",
    "    do_eval=True,  # whether to evaluate during training\n",
    "    do_train=True,  # whether to train the model\n",
    "    save_strategy='epoch',  # save the model after each epoch\n",
    "    evaluation_strategy='epoch',  # evaluate the model after each epoch\n",
    "    logging_strategy='steps',  # log steps instead of epochs for more frequent updates\n",
    "    report_to='tensorboard',  # report logs to TensorBoard\n",
    "    logging_steps=100,  # how often to log the training loss\n",
    "    fp16=True if torch.cuda.is_available() else False,  # whether to use mixed precision training\n",
    "    load_best_model_at_end=True,  # load the best model when finished training\n",
    "    metric_for_best_model='f1',  # use F1 score to determine best model\n",
    "    greater_is_better=True,  # higher F1 is better\n",
    "    seed=42,\n",
    "    dataloader_drop_last=True,  # drop last incomplete batch\n",
    "    gradient_accumulation_steps=2,  # accumulate gradients for effective larger batch size\n",
    "    save_total_limit=3,  # limit the total amount of checkpoints saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_487926/1123295968.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `MultilabelTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = MultilabelTrainer(model=model,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46860' max='46860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46860/46860 2:41:16, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.316611</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.842585</td>\n",
       "      <td>0.842585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.286011</td>\n",
       "      <td>0.853130</td>\n",
       "      <td>0.859742</td>\n",
       "      <td>0.859742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.273200</td>\n",
       "      <td>0.285596</td>\n",
       "      <td>0.853958</td>\n",
       "      <td>0.857415</td>\n",
       "      <td>0.857415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.282578</td>\n",
       "      <td>0.856274</td>\n",
       "      <td>0.862040</td>\n",
       "      <td>0.862040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.312477</td>\n",
       "      <td>0.846687</td>\n",
       "      <td>0.858307</td>\n",
       "      <td>0.858307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.361015</td>\n",
       "      <td>0.845211</td>\n",
       "      <td>0.848170</td>\n",
       "      <td>0.848170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.405244</td>\n",
       "      <td>0.842708</td>\n",
       "      <td>0.847916</td>\n",
       "      <td>0.847916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.469707</td>\n",
       "      <td>0.845564</td>\n",
       "      <td>0.846967</td>\n",
       "      <td>0.846967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.551106</td>\n",
       "      <td>0.844255</td>\n",
       "      <td>0.840125</td>\n",
       "      <td>0.840125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.597017</td>\n",
       "      <td>0.841422</td>\n",
       "      <td>0.844816</td>\n",
       "      <td>0.844816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.655869</td>\n",
       "      <td>0.840592</td>\n",
       "      <td>0.850345</td>\n",
       "      <td>0.850345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.713750</td>\n",
       "      <td>0.845396</td>\n",
       "      <td>0.853259</td>\n",
       "      <td>0.853259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.749595</td>\n",
       "      <td>0.846155</td>\n",
       "      <td>0.832470</td>\n",
       "      <td>0.832470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.791231</td>\n",
       "      <td>0.845129</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>0.841098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.840885</td>\n",
       "      <td>0.842641</td>\n",
       "      <td>0.834346</td>\n",
       "      <td>0.834346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.874575</td>\n",
       "      <td>0.841590</td>\n",
       "      <td>0.833322</td>\n",
       "      <td>0.833322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.897450</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>0.841693</td>\n",
       "      <td>0.841693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.926987</td>\n",
       "      <td>0.847590</td>\n",
       "      <td>0.843170</td>\n",
       "      <td>0.843170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.961740</td>\n",
       "      <td>0.845675</td>\n",
       "      <td>0.836349</td>\n",
       "      <td>0.836349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.997883</td>\n",
       "      <td>0.842938</td>\n",
       "      <td>0.847893</td>\n",
       "      <td>0.847893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.013787</td>\n",
       "      <td>0.846305</td>\n",
       "      <td>0.848116</td>\n",
       "      <td>0.848116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.037350</td>\n",
       "      <td>0.844888</td>\n",
       "      <td>0.848272</td>\n",
       "      <td>0.848272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.058569</td>\n",
       "      <td>0.846607</td>\n",
       "      <td>0.836659</td>\n",
       "      <td>0.836659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>1.078883</td>\n",
       "      <td>0.846632</td>\n",
       "      <td>0.844748</td>\n",
       "      <td>0.844748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.094583</td>\n",
       "      <td>0.845322</td>\n",
       "      <td>0.846397</td>\n",
       "      <td>0.846397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.097219</td>\n",
       "      <td>0.848023</td>\n",
       "      <td>0.846448</td>\n",
       "      <td>0.846448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.112198</td>\n",
       "      <td>0.848190</td>\n",
       "      <td>0.847128</td>\n",
       "      <td>0.847128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.116004</td>\n",
       "      <td>0.846805</td>\n",
       "      <td>0.845622</td>\n",
       "      <td>0.845622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.116145</td>\n",
       "      <td>0.849141</td>\n",
       "      <td>0.847925</td>\n",
       "      <td>0.847925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=46860, training_loss=0.06802474762131415, metrics={'train_runtime': 9676.3928, 'train_samples_per_second': 77.508, 'train_steps_per_second': 4.843, 'total_flos': 9.930927231138202e+16, 'train_loss': 0.06802474762131415, 'epoch': 29.98112})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = MultilabelTrainer(model=model, \n",
    "                            args=training_args, \n",
    "                            train_dataset=train_encoded, \n",
    "                            eval_dataset=val_encoded, \n",
    "                            compute_metrics=compute_metrics, \n",
    "                            tokenizer=tokenizer)\n",
    "\n",
    "trainer.train()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Test the performance of the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_res = trainer.predict(test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85702</td>\n",
       "      <td>0.862079</td>\n",
       "      <td>0.862079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1  precision    recall\n",
       "0  0.85702   0.862079  0.862079"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(compute_metrics(test_res[:2])).to_frame().transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
